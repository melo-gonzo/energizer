{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from typing import Any, Dict, Optional\n",
    "\n",
    "import torch\n",
    "from pytorch_lightning import LightningDataModule, LightningModule, Trainer, seed_everything\n",
    "from pytorch_lightning.trainer.states import RunningStage\n",
    "from torch import Tensor, nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchmetrics import F1, Accuracy, MetricCollection\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "from energizer.data import ActiveDataModule\n",
    "from energizer.inference import Deterministic\n",
    "from energizer.loops import ActiveLearningLoop\n",
    "from energizer.strategies import LeastConfidenceStrategy, RandomStrategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTDataModule(LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_dir: str = \"./data\",\n",
    "        batch_size: int = 32,\n",
    "        shuffle: Optional[bool] = False,\n",
    "        num_workers: int = 2,\n",
    "        pin_memory: bool = False,\n",
    "        drop_last: bool = False,\n",
    "        persistent_workers: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.num_workers = num_workers\n",
    "        self.pin_memory = pin_memory\n",
    "        self.drop_last = drop_last\n",
    "        self.persistent_workers = persistent_workers\n",
    "        self.transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "    def prepare_data(self):\n",
    "        MNIST(self.data_dir, train=True, download=True)\n",
    "        MNIST(self.data_dir, train=False, download=True)\n",
    "\n",
    "    def setup(self, stage: Optional[str] = None):\n",
    "\n",
    "        # Assign train/val datasets for use in dataloaders\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            mnist_full = MNIST(self.data_dir, train=True, transform=self.transform)\n",
    "            self.mnist_train, self.mnist_val = random_split(mnist_full, [55000, 5000])\n",
    "\n",
    "        # Assign test dataset for use in dataloader(s)\n",
    "        if stage == \"test\" or stage is None:\n",
    "            self.mnist_test = MNIST(self.data_dir, train=False, transform=self.transform)\n",
    "\n",
    "        if stage == \"predict\" or stage is None:\n",
    "            self.mnist_predict = MNIST(self.data_dir, train=False, transform=self.transform)\n",
    "\n",
    "    def _make_dataloader(self, dataset):\n",
    "        return DataLoader(\n",
    "            dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=self.shuffle,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=self.pin_memory,\n",
    "            drop_last=self.drop_last,\n",
    "            persistent_workers=self.persistent_workers,\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return self._make_dataloader(self.mnist_train)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return self._make_dataloader(self.mnist_val)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return self._make_dataloader(self.mnist_test)\n",
    "\n",
    "    def predict_dataloader(self):\n",
    "        return self._make_dataloader(self.mnist_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = MNISTDataModule(batch_size=128, num_workers=0)\n",
    "dm.prepare_data()\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(LightningModule):\n",
    "    def __init__(self, num_classes: int = 10) -> None:\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=5),\n",
    "            nn.Dropout2d(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=5),\n",
    "            nn.Dropout2d(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1024, 128),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(128, num_classes),\n",
    "        )\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "        metrics = MetricCollection([Accuracy(), F1(num_classes=num_classes, average=\"macro\")])\n",
    "        setattr(self, f\"{RunningStage.TRAINING}_metrics\", metrics.clone(prefix=\"train_\"))\n",
    "        setattr(self, f\"{RunningStage.VALIDATING}_metrics\", metrics.clone(prefix=\"val_\"))\n",
    "        setattr(self, f\"{RunningStage.TESTING}_metrics\", metrics.clone(prefix=\"test_\"))\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self.model(x)\n",
    "\n",
    "    def step(self, batch) -> None:\n",
    "        outputs = {}\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        outputs[\"loss\"] = self.loss(logits, y)\n",
    "\n",
    "        # detach to avoid future warning\n",
    "        outputs[\"targets\"] = y.detach()\n",
    "        outputs[\"logits\"] = logits.detach()\n",
    "        return outputs\n",
    "\n",
    "    def step_end(\n",
    "        self, outputs, running_stage: RunningStage, on_step: bool = True, on_epoch: bool = True, prog_bar: bool = True\n",
    "    ) -> None:\n",
    "        self.log(f\"{running_stage}_loss\", outputs[\"loss\"], on_step=on_step, on_epoch=on_epoch, prog_bar=prog_bar)\n",
    "        self.log_dict(\n",
    "            getattr(self, f\"{running_stage}_metrics\")(outputs[\"logits\"], outputs[\"targets\"]),\n",
    "            on_step=on_step,\n",
    "            on_epoch=on_epoch,\n",
    "            prog_bar=prog_bar,\n",
    "        )\n",
    "\n",
    "    def training_step(self, batch, *args, **kwargs) -> Dict[str, Any]:\n",
    "        return self.step(batch)\n",
    "\n",
    "    def training_step_end(self, outputs: Dict[str, Any]) -> None:\n",
    "        self.step_end(outputs, running_stage=RunningStage.TRAINING)\n",
    "\n",
    "    def validation_step(self, batch, *args, **kwargs) -> Dict[str, Any]:\n",
    "        return self.step(batch)\n",
    "\n",
    "    def validation_step_end(self, outputs: Dict[str, Any]) -> None:\n",
    "        self.step_end(outputs, running_stage=RunningStage.VALIDATING, on_step=False)\n",
    "\n",
    "    def test_step(self, batch, *args, **kwargs) -> Dict[str, Any]:\n",
    "        return self.step(batch)\n",
    "\n",
    "    def test_step_end(self, outputs: Dict[str, Any]) -> None:\n",
    "        self.step_end(outputs, running_stage=RunningStage.TESTING, on_step=False)\n",
    "\n",
    "    def predict_step(self, batch, *args, **kwargs) -> Tensor:\n",
    "        x, _ = batch\n",
    "        return self(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.SGD(self.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(1111)\n",
    "model = Model()\n",
    "trainer = Trainer(max_epochs=1)\n",
    "trainer.fit(model, datamodule=dm)\n",
    "trainer.test(model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1111\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name             | Type             | Params\n",
      "------------------------------------------------------\n",
      "0 | model            | Sequential       | 184 K \n",
      "1 | loss             | CrossEntropyLoss | 0     \n",
      "2 | train_metrics    | MetricCollection | 0     \n",
      "3 | validate_metrics | MetricCollection | 0     \n",
      "4 | test_metrics     | MetricCollection | 0     \n",
      "------------------------------------------------------\n",
      "184 K     Trainable params\n",
      "0         Non-trainable params\n",
      "184 K     Total params\n",
      "0.738     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH\n",
      "Active learning dataset: ActiveDataset({\n",
      "    original_dataset_size: 5000,\n",
      "    labelled_size: 1000,\n",
      "    pool_size: 4000,\n",
      "    base_class: <class 'torch.utils.data.dataset.Subset'>,\n",
      "})\n",
      "Testing:   0%|          | 0/5 [05:34<?, ?it/s].07it/s, loss=2.34, v_num=46, train_loss_step=2.340, train_Accuracy_step=0.108, train_F1_step=0.0954]\n",
      "Epoch 0: 100%|██████████| 6/6 [00:02<00:00,  2.45it/s, loss=2.34, v_num=46, train_loss_step=2.340, train_Accuracy_step=0.108, train_F1_step=0.0954, validate_loss=2.310, val_Accuracy=0.102, val_F1=0.0364, train_loss_epoch=2.340, train_Accuracy_epoch=0.108, train_F1_epoch=0.0954]\n",
      "Testing: 100%|██████████| 5/5 [00:01<00:00,  4.15it/s]--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_Accuracy': 0.10180000215768814,\n",
      " 'test_F1': 0.03642941266298294,\n",
      " 'test_loss': 2.3051962852478027}\n",
      "--------------------------------------------------------------------------------\n",
      "Testing: 100%|██████████| 5/5 [00:01<00:00,  3.64it/s]\n",
      "Testing: 100%|██████████| 4/4 [00:01<00:00,  3.66it/s]--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n",
      "Testing: 100%|██████████| 4/4 [00:01<00:00,  3.25it/s]\n",
      "\n",
      "EPOCH\n",
      "Active learning dataset: ActiveDataset({\n",
      "    original_dataset_size: 5000,\n",
      "    labelled_size: 1001,\n",
      "    pool_size: 3999,\n",
      "    base_class: <class 'torch.utils.data.dataset.Subset'>,\n",
      "})\n",
      "Epoch 0: 100%|██████████| 7/7 [00:02<00:00,  3.33it/s, loss=2.39, v_num=46, train_loss_step=2.460, train_Accuracy_step=0.000, train_F1_step=0.000, validate_loss=2.330, val_Accuracy=0.0942, val_F1=0.0172, train_loss_epoch=2.380, train_Accuracy_epoch=0.0999, train_F1_epoch=0.0862, test_loss=2.310, test_Accuracy=0.102, test_F1=0.0364]\n",
      "Testing: 100%|██████████| 5/5 [00:01<00:00,  4.21it/s]--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_Accuracy': 0.094200000166893,\n",
      " 'test_F1': 0.017197128385305405,\n",
      " 'test_loss': 2.3347675800323486}\n",
      "--------------------------------------------------------------------------------\n",
      "Testing: 100%|██████████| 5/5 [00:01<00:00,  3.74it/s]\n",
      "Testing: 100%|██████████| 4/4 [00:01<00:00,  3.64it/s]--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n",
      "Testing: 100%|██████████| 4/4 [00:01<00:00,  3.28it/s]\n",
      "\n",
      "EPOCH\n",
      "Active learning dataset: ActiveDataset({\n",
      "    original_dataset_size: 5000,\n",
      "    labelled_size: 1002,\n",
      "    pool_size: 3998,\n",
      "    base_class: <class 'torch.utils.data.dataset.Subset'>,\n",
      "})\n",
      "Epoch 0: 100%|██████████| 7/7 [00:02<00:00,  3.37it/s, loss=2.33, v_num=46, train_loss_step=2.070, train_Accuracy_step=0.500, train_F1_step=0.333, validate_loss=2.320, val_Accuracy=0.113, val_F1=0.0366, train_loss_epoch=2.380, train_Accuracy_epoch=0.102, train_F1_epoch=0.0902, test_loss=2.330, test_Accuracy=0.0942, test_F1=0.0172]   \n",
      "Testing: 100%|██████████| 5/5 [00:01<00:00,  4.19it/s]--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_Accuracy': 0.1128000020980835,\n",
      " 'test_F1': 0.03659426048398018,\n",
      " 'test_loss': 2.3204782009124756}\n",
      "--------------------------------------------------------------------------------\n",
      "Testing: 100%|██████████| 5/5 [00:01<00:00,  3.69it/s]\n",
      "Testing: 100%|██████████| 4/4 [00:01<00:00,  3.58it/s]--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n",
      "Testing: 100%|██████████| 4/4 [00:01<00:00,  3.16it/s]\n",
      "\n",
      "EPOCH\n",
      "Active learning dataset: ActiveDataset({\n",
      "    original_dataset_size: 5000,\n",
      "    labelled_size: 1003,\n",
      "    pool_size: 3997,\n",
      "    base_class: <class 'torch.utils.data.dataset.Subset'>,\n",
      "})\n",
      "Epoch 0: 100%|██████████| 7/7 [00:02<00:00,  3.16it/s, loss=2.36, v_num=46, train_loss_step=2.510, train_Accuracy_step=0.000, train_F1_step=0.000, validate_loss=2.310, val_Accuracy=0.135, val_F1=0.0529, train_loss_epoch=2.360, train_Accuracy_epoch=0.110, train_F1_epoch=0.100, test_loss=2.320, test_Accuracy=0.113, test_F1=0.0366] \n",
      "Testing: 100%|██████████| 5/5 [00:01<00:00,  3.89it/s]--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_Accuracy': 0.13459999859333038,\n",
      " 'test_F1': 0.05289089307188988,\n",
      " 'test_loss': 2.3093302249908447}\n",
      "--------------------------------------------------------------------------------\n",
      "Testing: 100%|██████████| 5/5 [00:01<00:00,  3.48it/s]\n",
      "Testing: 100%|██████████| 4/4 [00:01<00:00,  3.70it/s]--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n",
      "Testing: 100%|██████████| 4/4 [00:01<00:00,  3.33it/s]\n",
      "\n",
      "EPOCH\n",
      "Active learning dataset: ActiveDataset({\n",
      "    original_dataset_size: 5000,\n",
      "    labelled_size: 1004,\n",
      "    pool_size: 3996,\n",
      "    base_class: <class 'torch.utils.data.dataset.Subset'>,\n",
      "})\n",
      "Epoch 0: 100%|██████████| 7/7 [00:02<00:00,  3.37it/s, loss=2.37, v_num=46, train_loss_step=2.450, train_Accuracy_step=0.000, train_F1_step=0.000, validate_loss=2.310, val_Accuracy=0.121, val_F1=0.0441, train_loss_epoch=2.370, train_Accuracy_epoch=0.0966, train_F1_epoch=0.0845, test_loss=2.310, test_Accuracy=0.135, test_F1=0.0529]\n",
      "Testing: 100%|██████████| 5/5 [00:01<00:00,  4.13it/s]--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_Accuracy': 0.12099999934434891,\n",
      " 'test_F1': 0.04414382949471474,\n",
      " 'test_loss': 2.311419725418091}\n",
      "--------------------------------------------------------------------------------\n",
      "Testing: 100%|██████████| 5/5 [00:01<00:00,  3.67it/s]\n",
      "Testing: 100%|██████████| 4/4 [00:01<00:00,  3.88it/s]--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n",
      "Testing: 100%|██████████| 4/4 [00:01<00:00,  3.49it/s]\n",
      "\n",
      "EPOCH\n",
      "Active learning dataset: ActiveDataset({\n",
      "    original_dataset_size: 5000,\n",
      "    labelled_size: 1005,\n",
      "    pool_size: 3995,\n",
      "    base_class: <class 'torch.utils.data.dataset.Subset'>,\n",
      "})\n",
      "Epoch 0: 100%|██████████| 7/7 [00:02<00:00,  3.36it/s, loss=2.34, v_num=46, train_loss_step=2.010, train_Accuracy_step=0.600, train_F1_step=0.444, validate_loss=2.300, val_Accuracy=0.113, val_F1=0.0472, train_loss_epoch=2.400, train_Accuracy_epoch=0.0975, train_F1_epoch=0.0856, test_loss=2.310, test_Accuracy=0.121, test_F1=0.0441] \n",
      "Testing: 100%|██████████| 5/5 [00:01<00:00,  4.01it/s]--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_Accuracy': 0.1128000020980835,\n",
      " 'test_F1': 0.04722326621413231,\n",
      " 'test_loss': 2.30245304107666}\n",
      "--------------------------------------------------------------------------------\n",
      "Testing: 100%|██████████| 5/5 [00:01<00:00,  3.46it/s]\n",
      "Testing: 100%|██████████| 4/4 [00:01<00:00,  3.71it/s]--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n",
      "Testing: 100%|██████████| 4/4 [00:01<00:00,  3.33it/s]\n",
      "\n",
      "EPOCH\n",
      "Active learning dataset: ActiveDataset({\n",
      "    original_dataset_size: 5000,\n",
      "    labelled_size: 1006,\n",
      "    pool_size: 3994,\n",
      "    base_class: <class 'torch.utils.data.dataset.Subset'>,\n",
      "})\n",
      "Epoch 0: 100%|██████████| 7/7 [00:02<00:00,  3.37it/s, loss=2.33, v_num=46, train_loss_step=2.230, train_Accuracy_step=0.000, train_F1_step=0.000, validate_loss=2.300, val_Accuracy=0.106, val_F1=0.0279, train_loss_epoch=2.380, train_Accuracy_epoch=0.0895, train_F1_epoch=0.081, test_loss=2.300, test_Accuracy=0.113, test_F1=0.0472]  \n",
      "Testing: 100%|██████████| 5/5 [00:01<00:00,  4.21it/s]--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_Accuracy': 0.10639999806880951,\n",
      " 'test_F1': 0.02788606658577919,\n",
      " 'test_loss': 2.3017430305480957}\n",
      "--------------------------------------------------------------------------------\n",
      "Testing: 100%|██████████| 5/5 [00:01<00:00,  3.76it/s]\n",
      "Testing: 100%|██████████| 4/4 [00:01<00:00,  3.71it/s]--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n",
      "Testing: 100%|██████████| 4/4 [00:01<00:00,  3.34it/s]\n",
      "\n",
      "EPOCH\n",
      "Active learning dataset: ActiveDataset({\n",
      "    original_dataset_size: 5000,\n",
      "    labelled_size: 1007,\n",
      "    pool_size: 3993,\n",
      "    base_class: <class 'torch.utils.data.dataset.Subset'>,\n",
      "})\n",
      "Epoch 0: 100%|██████████| 7/7 [00:02<00:00,  3.34it/s, loss=2.34, v_num=46, train_loss_step=2.430, train_Accuracy_step=0.143, train_F1_step=0.0625, validate_loss=2.300, val_Accuracy=0.115, val_F1=0.0613, train_loss_epoch=2.380, train_Accuracy_epoch=0.0924, train_F1_epoch=0.081, test_loss=2.300, test_Accuracy=0.106, test_F1=0.0279]\n",
      "Testing: 100%|██████████| 5/5 [00:01<00:00,  4.27it/s]--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_Accuracy': 0.1151999980211258,\n",
      " 'test_F1': 0.061342425644397736,\n",
      " 'test_loss': 2.301313638687134}\n",
      "--------------------------------------------------------------------------------\n",
      "Testing: 100%|██████████| 5/5 [00:01<00:00,  3.78it/s]\n",
      "Testing: 100%|██████████| 4/4 [00:01<00:00,  3.68it/s]--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n",
      "Testing: 100%|██████████| 4/4 [00:01<00:00,  3.32it/s]\n",
      "\n",
      "EPOCH\n",
      "Active learning dataset: ActiveDataset({\n",
      "    original_dataset_size: 5000,\n",
      "    labelled_size: 1008,\n",
      "    pool_size: 3992,\n",
      "    base_class: <class 'torch.utils.data.dataset.Subset'>,\n",
      "})\n",
      "Epoch 0: 100%|██████████| 7/7 [00:02<00:00,  3.17it/s, loss=2.34, v_num=46, train_loss_step=2.270, train_Accuracy_step=0.125, train_F1_step=0.0952, validate_loss=2.300, val_Accuracy=0.127, val_F1=0.0476, train_loss_epoch=2.370, train_Accuracy_epoch=0.0913, train_F1_epoch=0.0818, test_loss=2.300, test_Accuracy=0.115, test_F1=0.0613]\n",
      "Testing: 100%|██████████| 5/5 [00:01<00:00,  4.21it/s]--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_Accuracy': 0.1265999972820282,\n",
      " 'test_F1': 0.047584228217601776,\n",
      " 'test_loss': 2.2994658946990967}\n",
      "--------------------------------------------------------------------------------\n",
      "Testing: 100%|██████████| 5/5 [00:01<00:00,  3.74it/s]\n",
      "Testing: 100%|██████████| 4/4 [00:01<00:00,  3.38it/s]--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n",
      "Testing: 100%|██████████| 4/4 [00:01<00:00,  3.04it/s]\n",
      "\n",
      "EPOCH\n",
      "Active learning dataset: ActiveDataset({\n",
      "    original_dataset_size: 5000,\n",
      "    labelled_size: 1009,\n",
      "    pool_size: 3991,\n",
      "    base_class: <class 'torch.utils.data.dataset.Subset'>,\n",
      "})\n",
      "Epoch 0: 100%|██████████| 7/7 [00:02<00:00,  2.87it/s, loss=2.36, v_num=46, train_loss_step=2.580, train_Accuracy_step=0.111, train_F1_step=0.0741, validate_loss=2.300, val_Accuracy=0.107, val_F1=0.0239, train_loss_epoch=2.390, train_Accuracy_epoch=0.0912, train_F1_epoch=0.0795, test_loss=2.300, test_Accuracy=0.127, test_F1=0.0476]\n",
      "Testing:  20%|██        | 1/5 [00:00<00:01,  2.26it/s]"
     ]
    }
   ],
   "source": [
    "seed_everything(1111)\n",
    "adm = ActiveDataModule(\n",
    "    num_workers=0,\n",
    "    train_dataset=dm.mnist_val,\n",
    "    val_dataset=dm.mnist_val,\n",
    "    test_dataset=dm.mnist_val,\n",
    "    num_classes=10,\n",
    "    initial_labels=1_000,\n",
    "    batch_size=1_000,\n",
    ")\n",
    "model = Model(num_classes=adm.num_classes)\n",
    "trainer = Trainer(max_epochs=1)\n",
    "active_learning_loop = ActiveLearningLoop(\n",
    "    # strategy=RandomStrategy(),\n",
    "    strategy=LeastConfidenceStrategy(inference_module=Deterministic()),\n",
    "    query_size=1,\n",
    "    total_budget=2_000,\n",
    "    reset_weights=True,\n",
    ")\n",
    "active_learning_loop.connect(trainer)\n",
    "trainer.fit_loop = active_learning_loop\n",
    "trainer.fit(model, datamodule=adm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "195fd7177374df90e8fb0ddf6905c3c94c4a4300f1cc015456754f40bbdfd90b"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('energizer-dev': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
